{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the effects of ownership on software quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Case Of Lucene##\n",
    "We want to replicate the study (http://dl.acm.org/citation.cfm?doid=2025113.2025119) done by Bird et al.\n",
    "and published in FSE'11. The idea is to see the results of a similar investigation on an OSS system. We\n",
    "select Lucene (https://lucene.apache.org/core/), a search engine written in Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection##\n",
    "First we need to get the data to create our table, in other words we do what is called data collection.\n",
    "\n",
    "In our case, we are interested in checking the relation between some ownership related metrics and post-\n",
    "release bugs. We investigate this relation at file level, because we focus on Java and in this language the\n",
    "building blocks are the classes, which most of the time correspond 1-to-1 to files.\n",
    "\n",
    "This means that our table will have one row per each source code file and as many columns as the metrics\n",
    "we want to compute for that file, plus one column with the number of post release bugs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting git data\n",
    "For computing most of the metrics we want to investigate (e.g., how many people changed a file in its entire\n",
    "history) we need to know the history of files. We can do so by analyzing the versioning system. In our case,\n",
    "Lucene has a Subversion repository, but a git mirror (https://github.com/apache/lucene-solr.git) is also\n",
    "available. We use the git repository as it allows to have the entire history locally, thus making the\n",
    "computations faster.\n",
    "\n",
    "We clone the repository. For this we use the python library 'sh'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sh\n",
    "import json\n",
    "import os\n",
    "import glob2\n",
    "from collections import Counter\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.getcwd() + '/lucene-solr'):\n",
    "    print(\"Path doesn\\'t exists, cloning repo:\")\n",
    "    sh.git.clone(\"https://github.com/apache/lucene-solr.git\")\n",
    "else:\n",
    "    print(\"Repository exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "git = sh.git.bake(_cwd='lucene-solr')\n",
    "git.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the replication, we can either reason in terms of releases (see list of Lucene releases\n",
    "(http://archive.apache.org/dist/lucene/java/)), or we can just inspect the 'trunk' in the versioning system and\n",
    "start from a given date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We decided to reason in terms of releases**.\n",
    "\n",
    "We first check which releases can be found in the git repository: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = git.tag() # To show all the tags\n",
    "versions = []\n",
    "for t in tags:\n",
    "    if t.startswith('lucene_solr_'):\n",
    "        versions.append(t[12:-1].replace('_','.')) #extract the version, remove the \\n\n",
    "\n",
    "versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug extraction ##\n",
    "We want to count the number of bugs for every .java file. To do that we follow these steps: \n",
    "1. Select a version of the software: we will find and use the one with more bugs, so that we can have more data;\n",
    "2. Find the bugs that affect that version;\n",
    "3. For every bug, find the commit(s) that fixed it: it is easy to do it in the Lucene repository because if a commit fixes the bug with key=LUCENE-123 then it has, by convention, the keyword LUCENE-123 in the commit message. \n",
    "4. For every commit in the resulting list, get the files that it modified. If a file was modified by a bug-fixing commit it means that it was the one with the bug, so for every one of these file the bug count is incremented by one.\n",
    "\n",
    "We first define two methods:\n",
    "* extract_bug(file): extracts the bug object from the corresponding .json file. It returns None if it is not a bug (e.g. it can be an 'Improvement') or if it is not marked as 'Fixed';\n",
    "* extract_version_bugs(file): extracts a list of all the bugs that affect a specific version;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_bug(file):\n",
    "    if not file.endswith('.json'):\n",
    "            return None\n",
    "    else:\n",
    "        bug_json_string = open(\"issue_LUCENE/\" + file).read()\n",
    "        bug = json.loads(bug_json_string)\n",
    "        bug_fields = bug.get('fields')\n",
    "        \n",
    "        if bug_fields['issuetype']['name'] != 'Bug':\n",
    "            return None\n",
    "   \n",
    "        if bug_fields['resolution'] == None:\n",
    "            return None \n",
    "                \n",
    "        if bug_fields['resolution']['name'] != 'Fixed':\n",
    "            return None\n",
    "    return bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_version_bugs(version):\n",
    "    if version.endswith('.0'):\n",
    "        version = version[:-2]\n",
    "\n",
    "    version_bugs = []\n",
    "    for file in os.listdir(os.getcwd() + \"/issue_LUCENE\"):\n",
    "        bug = extract_bug(file)\n",
    "        if(bug == None):\n",
    "            continue\n",
    "            \n",
    "        affected_versions = bug['fields']['versions']\n",
    "        if len(affected_versions) == 0:\n",
    "            continue\n",
    "        else:    \n",
    "            for v in affected_versions:\n",
    "                n = v['name']\n",
    "                if (n == version) or (n == version + '.0'):\n",
    "                    version_bugs.append(bug)\n",
    "    return version_bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most buggy release ###\n",
    "The first thing that we need to do is select a release: we want to find the one with more bugs.\n",
    "\n",
    "The following block counts the number of bugs that affect every release, and that are now fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "version_bugs_count = dict()\n",
    "for file in os.listdir(os.getcwd() + \"/issue_LUCENE\"):\n",
    "       \n",
    "    bug = extract_bug(file)\n",
    "    if(bug == None):\n",
    "        continue\n",
    "         \n",
    "    affected_versions = bug['fields']['versions']\n",
    "    if len(affected_versions) == 0:\n",
    "        continue\n",
    "    else:    \n",
    "        for v in affected_versions:\n",
    "            n = v['name']\n",
    "            if(version_bugs_count.get(n) == None):\n",
    "                version_bugs_count[n] = 1\n",
    "            else:\n",
    "                version_bugs_count[n] = version_bugs_count[n] + 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the resulting dictionary to find and checkout the release that is available as a tag in the repository and that has the highest number of bugs (we discard ALPHA or BETA versions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_bugged_version = max(version_bugs_count, key=version_bugs_count.get)\n",
    "while ((most_bugged_version.find('ALPHA') != -1) or\n",
    "       (most_bugged_version.find('BETA') != -1) or\n",
    "       ((most_bugged_version not in versions) and (most_bugged_version + \".0\" not in versions))):\n",
    "        \n",
    "    version_bugs_count.pop(most_bugged_version)\n",
    "    most_bugged_version = max(version_bugs_count, key=version_bugs_count.get)\n",
    "\n",
    "print(\"The release with the highest number of bugs is version \" + most_bugged_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "version = most_bugged_version\n",
    "git.checkout(\"tags/lucene_solr_\" + version.replace('.','_').replace('-','_0_'))\n",
    "git.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bug count ###\n",
    "Now that we selected a version we want to apply the described bug counting procedure.\n",
    "We first extract the bugs that affects it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bugs = extract_version_bugs(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following blocks extract the commits that fixed every bug in the list, and for every commit the bug count is incremented for every .java file that it affects.\n",
    "\n",
    "We use the **git log** command, with the grep option, to find the commits, and then every commit is shown with the **git show** command: this shows only the affected files because the pretty=format option is leaved empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commits = []\n",
    "for b in bugs:\n",
    "    log = git.log(\"--all\", \"--grep=\" + b['key'], \"--pretty=format:%H\")\n",
    "    for c_hash in log:\n",
    "        if(c_hash.endswith('\\n')):\n",
    "            c_hash = c_hash[:-1]\n",
    "        commits.append(c_hash)\n",
    "\n",
    "commits = set(commits) #To avoid considering the same commit more times (e.g. if a commit fixed more than one bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_bugs = dict()\n",
    "for commit in commits:\n",
    "    details = git.show(\"--name-only\",\"--pretty=format:\",commit)\n",
    "    for file in details:\n",
    "        if(file.endswith('\\n')):\n",
    "            file = file[:-1]\n",
    "        if(file.endswith('.java')):\n",
    "            file = file # .split('/')[-1]\n",
    "            if(file_bugs.get(file) == None):\n",
    "                file_bugs[file] = 1\n",
    "            else:\n",
    "                file_bugs[file] = file_bugs[file] + 1\n",
    "\n",
    "file_bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dictionary that contains the bug count for every file (that has bugs), and we can use it later to build the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ownsership metrics ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all java files\n",
    "\n",
    "To be able to compute the metrics for all the java files it is necessary to find the location of them in the repository. This is done by recursively going through the repository and storing all the file locations so that they can later be used to get the log message through git.\n",
    "\n",
    "**We decided to use the whole file path (relative to the root of the repository), because there are files with the same name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "java_file_list = []\n",
    "cdir = os.getcwd()\n",
    "os.chdir(cdir + '/lucene-solr')\n",
    "\n",
    "## All files\n",
    "for file_location in glob2.glob('*/**/*.java'):\n",
    "    java_file_list.append(file_location)\n",
    "    \n",
    "os.chdir(cdir)\n",
    "\n",
    "print(\"Number of Java files: \" + str(len(java_file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the metrics for every file\n",
    "\n",
    "Computing the metrics is done by looking at the log of every java file found by globbing througth the repository recursively. We are only interested in the contributors of every commit. We will compute the following metrics:\n",
    "\n",
    "* **Major**: Number of minor contributors (developers whose ownership on the code in the file is less than the 5%);\n",
    "* **Minor**: Number of major contributors (developers whose ownership on the code in the file is more than or equal to the 5%);\n",
    "* **Total**: Total number of contributors;\n",
    "* **Ownership**: Proportion of ownership for the contributor with the highest proportion of ownership.\n",
    "\n",
    "Method:\n",
    "\n",
    "1. Retrieve commit log through git;\n",
    "2. Convert the log message into a list, so every entry contains the name of the developer that made a commit to the file;\n",
    "3. Calculate the metrics (**Major**, **Minor**, **Total** and **Ownership** );\n",
    "4. Do this for all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File -  Minor - Major - Total - Ownership\n",
    "data_set = []\n",
    "\n",
    "# file_name = java_file_list[0]\n",
    "for file_name in java_file_list:\n",
    "    # Name\n",
    "    persons = set()\n",
    "\n",
    "    # Metrics\n",
    "    major = 0\n",
    "    minor = 0\n",
    "    total = 0\n",
    "    ownership = 0;\n",
    "\n",
    "    # Get Log data from git\n",
    "    var = git.log(\"--pretty=format:%an\", \"--follow\", file_name)\n",
    "    developers_of_commits = var.split('\\n')\n",
    "\n",
    "    # Determine commits per developer\n",
    "    c = Counter(developers_of_commits)\n",
    "\n",
    "    # Get set of developers and calculate total number of commits\n",
    "    for name_dev in developers_of_commits:\n",
    "        if name_dev not in persons:\n",
    "            persons.add(name_dev) # Unique set of developers of this file\n",
    "            total = total + c[name_dev] # Total number of commits of this file\n",
    "\n",
    "    # Compute metrics\n",
    "    for name in persons:\n",
    "        contribution_perc = c[name]/total\n",
    "        if contribution_perc >= 0.05:\n",
    "            major = major + 1\n",
    "        elif contribution_perc < 0.05:\n",
    "            minor = minor + 1\n",
    "\n",
    "        if ownership < contribution_perc:\n",
    "            ownership = contribution_perc\n",
    "\n",
    "    # Add computed data to the data_set\n",
    "    data_set.append([file_name, minor, major, len(persons), ownership])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the computed metrics and the bug count into a  .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myfile = open(filename, 'w')\n",
    "wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "wr.writerow(['File', 'Minor', 'Major', 'Total', 'Ownership', 'Bugs'])\n",
    "for row in data_set:\n",
    "    if file_bugs.get(row[0]) != None:\n",
    "        row.append(file_bugs[row[0]])\n",
    "    else:\n",
    "        row.append(0)\n",
    "    wr.writerow(row)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
