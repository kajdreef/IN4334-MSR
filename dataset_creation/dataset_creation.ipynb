{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sh\n",
    "import json\n",
    "import os\n",
    "import glob2\n",
    "from collections import Counter\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(i, l, step=1):\n",
    "    if i % step == 0:\n",
    "            print(\"\\r>> {}/{}\".format(i + 1, l), end=\"\")\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LUCENE-SOLR\n",
    "project_folder = \"lucene\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"lucene-solr\"\n",
    "repository_link = \"https://github.com/apache/lucene-solr.git\"\n",
    "checkout_branch = \"trunk\"\n",
    "\n",
    "issues_folders = [\"issue_LUCENE\", \"issue_SOLR\"]\n",
    "issues_tags = [\"LUCENE\", \"SOLR\"]\n",
    "end = \"2015-01-01\"\n",
    "start = \"Mar 18 2010\"\n",
    "\n",
    "implicated_list_file = output_folder + '/' + project_folder + '_implicated_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CAMEL\n",
    "project_folder = \"camel\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"camel\"\n",
    "repository_link = \"https://github.com/apache/camel\"\n",
    "checkout_branch = \"master\"\n",
    "\n",
    "issues_folders = [\"issue_CAMEL\"]\n",
    "issues_tags = [\"CAMEL\"]\n",
    "end = \"2015-01-01\"\n",
    "start = \"Mar 20 2007\"\n",
    "\n",
    "implicated_list_file = output_folder + '/' + project_folder + '_implicated_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ZOOKEEPER\n",
    "project_folder = \"zookeeper\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"zookeeper\"\n",
    "repository_link = \"https://github.com/apache/zookeeper\"\n",
    "checkout_branch = \"trunk\"\n",
    "\n",
    "issues_folders = [\"issue_ZOOKEEPER\"]\n",
    "issues_tags = [\"ZOOKEEPER\"]\n",
    "end = \"2015-01-01\"\n",
    "start = \"Nov 3 2007\"\n",
    "\n",
    "implicated_list_file = output_folder + '/' + project_folder + '_implicated_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAVEN\n",
    "project_folder = \"maven\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"maven\"\n",
    "repository_link = \"https://github.com/apache/maven\"\n",
    "checkout_branch = \"master\"\n",
    "\n",
    "issues_folders = [\"issue_MNG\"]\n",
    "issues_tags = [\"MNG\"]\n",
    "end = \"2015-01-01\"\n",
    "start = \"2004-01-01\"\n",
    "\n",
    "implicated_list_file = output_folder + '/' + project_folder + '_implicated_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAHOUT\n",
    "project_folder = \"mahout\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"mahout\"\n",
    "repository_link = \"https://github.com/apache/mahout\"\n",
    "checkout_branch = \"master\"\n",
    "\n",
    "issues_folders = [\"issue_MAHOUT\"]\n",
    "issues_tags = [\"MAHOUT\"]\n",
    "end = \"2015-01-01\"\n",
    "start = \"Feb 20 2008\"\n",
    "\n",
    "implicated_list_file = output_folder + '/' + project_folder + '_implicated_files.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.getcwd() + '/' + project_folder + '/' + repository_folder):\n",
    "    print(\"Path doesn\\'t exists, cloning repo:\")\n",
    "    git = sh.git.bake(_cwd=project_folder)\n",
    "    git.clone(repository_link)\n",
    "else:\n",
    "    print(\"Repository exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "On branch master\n",
       "Your branch is up-to-date with 'origin/master'.\n",
       "\n",
       "\n",
       "It took 3.85 seconds to enumerate untracked files. 'status -uno'\n",
       "may speed it up, but you have to be careful not to forget to add\n",
       "new files yourself (see 'git help status').\n",
       "nothing to commit, working directory clean"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git = sh.git.bake(_cwd=project_folder + '/' + repository_folder)\n",
    "git.checkout(checkout_branch)\n",
    "git.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits = []\n",
    "\n",
    "log = git.log(\"--reverse\", \"--pretty=format:%H\", '--before=\"{}\"'.format(end), '--after=\"{}\"'.format(start))\n",
    "for c_hash in log:\n",
    "    if(c_hash.endswith('\\n')):\n",
    "        c_hash = c_hash[:-1]\n",
    "    commits.append(c_hash)\n",
    "len(commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Changes = namedtuple('Changes', 'added, deleted')\n",
    "\n",
    "def count_changes(commit_hash, file_matching_regexp = '.*\\.java'):\n",
    "    files = git.show(\"--name-only\",\"--pretty=format:\",commit_hash)\n",
    "    changes_count = dict() #This will be filled with tuples: (lines_added, lines_deleted)\n",
    "    for f in files:\n",
    "        f = f[:-1]\n",
    "        m = re.findall(file_matching_regexp, f)\n",
    "        if len(m) == 0:\n",
    "                continue\n",
    "        diff = str(git.diff(\"--stat\", commit_hash + \"^\", commit_hash, \"--\", f))\n",
    "        m = re.findall(\"[0-9]+ insertion\", diff)\n",
    "        if len(m) == 0:\n",
    "            added = 0\n",
    "        else:\n",
    "            added = int(m[0].split(' ')[0])\n",
    "        m = re.findall(\"[0-9]+ deletion\", diff)\n",
    "        if len(m) == 0:\n",
    "            deleted = 0\n",
    "        else:\n",
    "            deleted = int(m[0].split(' ')[0])\n",
    "\n",
    "        changes_count[f] = Changes(added, deleted)\n",
    "\n",
    "    return changes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_authorship(blame_output, authors_list):\n",
    "    authorship = dict()\n",
    "    for i in authors_list:\n",
    "        m = re.findall(i, str(blame))\n",
    "        authorship[i] = len(m)\n",
    "    return authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_comments(blame_output):\n",
    "    #Tested: the result of counting the lines of comments on the blame output or on the source code is the same\n",
    "    regex = re.compile(\"(?://[^\\n]*|/\\*(?:(?!\\*/).)*\\*/)\", re.DOTALL)\n",
    "    m = regex.findall(str(blame_output))\n",
    "    return sum([len(c.split('\\n')) for c in m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_complete_authorship(sha, file_path):\n",
    "    blame = git.blame(\"-e\", sha, \"--\", file_path)\n",
    "    m = re.findall(\"\\(<.+?>\", str(blame))\n",
    "    authors = []\n",
    "    for a in m:\n",
    "        authors.append(a[2:-1])\n",
    "    #print(set(authors))\n",
    "    authorship = dict()\n",
    "    for i in set(authors):\n",
    "        m = re.findall(i, str(blame))\n",
    "        #print(m)\n",
    "        authorship[i] = len(m)\n",
    "    return authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_counters(file_dict, file_name, author, changes):\n",
    "#Create/update file entries in the dict()\n",
    "    if file_dict.get(file_name) == None:\n",
    "        file_dict[file_name] = SimpleNamespace()\n",
    "        f = file_dict[file_name]\n",
    "        f.author_dict = dict()\n",
    "        f.tot_lines_added = 0\n",
    "        f.tot_lines_deleted = 0\n",
    "        f.tot_commits = 0\n",
    "         \n",
    "    f = file_dict[file_name]\n",
    "    f.tot_lines_added += changes.added\n",
    "    f.tot_lines_deleted += changes.deleted\n",
    "    f.tot_commits += 1\n",
    "     \n",
    "#Create/update author entries in the dict() for that file\n",
    "    if f.author_dict.get(author) == None:\n",
    "        f.author_dict[author] = SimpleNamespace()\n",
    "        a = f.author_dict[author]\n",
    "        a.lines_added = 0\n",
    "        a.lines_deleted = 0\n",
    "        a.commits = 0\n",
    "        \n",
    "    a = f.author_dict[author]\n",
    "    a.lines_added += changes.added\n",
    "    a.lines_deleted += changes.deleted\n",
    "    a.commits += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_bug(file_path):\n",
    "    if not file.endswith('.json'):\n",
    "            return None\n",
    "    else:\n",
    "        bug_json_string = open(file_path).read()\n",
    "        bug = json.loads(bug_json_string)\n",
    "        bug_fields = bug.get('fields')\n",
    "        \n",
    "        if bug_fields['issuetype']['name'] != 'Bug':\n",
    "            return None\n",
    "   \n",
    "        if bug_fields['resolution'] == None:\n",
    "            return None \n",
    "                \n",
    "        if bug_fields['resolution']['name'] != 'Fixed':\n",
    "            return None\n",
    "    return bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress for issue_CAMEL:\n",
      ">> 9001/9002\n",
      "2525 fixed bugs extracted.\n"
     ]
    }
   ],
   "source": [
    "#Extracting all the fixed bugs from the bug repo\n",
    "bugs = dict() #Dictionary of bugs indexed by TAG+ID (e.g. LUCENE-1234)\n",
    "for fld in issues_folders:\n",
    "    path = project_folder + '/' + fld\n",
    "    dir_list = os.listdir(os.getcwd() + '/' + path)\n",
    "    l = len(dir_list)\n",
    "    print()\n",
    "    print(\"Progress for \" + fld + \":\")\n",
    "    for idx, file in enumerate(dir_list):\n",
    "        print_progress(idx,l,10)\n",
    "        bug = extract_bug(path + '/' + file)\n",
    "        if(bug == None):\n",
    "            continue\n",
    "        bugs[bug['key'].upper()] = bug\n",
    "\n",
    "print()\n",
    "print(len(bugs), \"fixed bugs extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = output_folder + '/' + project_folder + '_issue_dates.csv'\n",
    "file = open(filename, 'w')\n",
    "wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "wr.writerow(['issue_key', 'created', 'resolutiondate', 'days_to_solve'])\n",
    "for key,bug in bugs.items():\n",
    "    c_date = bug['fields']['created']\n",
    "    r_date = bug['fields']['resolutiondate']\n",
    "    c_date = datetime.strptime(c_date[:10], \"%Y-%m-%d\")\n",
    "    r_date = datetime.strptime(r_date[:10], \"%Y-%m-%d\")\n",
    "    #print(c_date.date(), r_date.date(), (r_date - c_date).days)\n",
    "    wr.writerow([bug['key'], c_date.date(), r_date.date(), (r_date - c_date).days])\n",
    "#resolutiondate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fixed_bugs(commit_hash):\n",
    "    details = git.show(\"--name-only\",\"--pretty=format:%B\", commit_hash)\n",
    "    #init = details.split(':')[0].upper()\n",
    "    f_keys = []\n",
    "    \n",
    "    for tag in issues_tags:\n",
    "        keys = re.findall(tag + \"-[0-9]+\",str(details))\n",
    "        if len(keys) != 0:\n",
    "            for k in keys:\n",
    "                if bugs.get(k) != None:\n",
    "                    #Then it fixes a bug\n",
    "                    f_keys.append(k)\n",
    "    return f_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_affected_versions(fixed_bug_keys):\n",
    "    affected_versions = []\n",
    "    for b in fixed_bug_keys:\n",
    "        versions = bugs[b]['fields']['versions']\n",
    "        if len(versions) == 0:\n",
    "            continue\n",
    "        else:    \n",
    "            for v in versions:\n",
    "                n = v['name']\n",
    "                affected_versions.append(n)\n",
    "    return affected_versions\n",
    "#e.g. \n",
    "#get_affected_versions(['LUCENE-2244', 'LUCENE-3255'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 158/18388"
     ]
    }
   ],
   "source": [
    "l = len(commits)\n",
    "\n",
    "file_dict = dict()\n",
    "\n",
    "columns = '''project, file, sha, author, \n",
    "author_file_tot_added, author_file_added_this_commit, file_tot_added, \n",
    "author_file_tot_deleted, author_file_deleted_this_commit, file_tot_deleted, \n",
    "author_file_commits, file_tot_commits, \n",
    "current_lines_authored, current_file_size, current_comment_lines, \n",
    "max_current_author, total_current_authors, \n",
    "commit_date, \n",
    "bug_fix, fixed_bugs, affected_versions'''\n",
    "\n",
    "filename = output_folder + '/' + project_folder + '_out.csv'\n",
    "file = open(filename, 'w')\n",
    "wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "wr.writerow(columns.replace('\\n', '').split(', '))\n",
    "\n",
    "for idx, commit_hash in enumerate(commits):\n",
    "    print_progress(idx, l)\n",
    "    s = str(git.show(\"--name-only\", '--format=\"%aN <%aE>\"', commit_hash)).split('\\n')[0].split('<')\n",
    "    author_name = s[0][1:-1]\n",
    "    #author_email = s[1][:-2]\n",
    "    date = str(git.show(\"-s\", \"--format=%ci\", commit_hash))[:-1].replace(\"\\n\", '')\n",
    "    file_changes = count_changes(commit_hash)\n",
    "    \n",
    "    #Checking if it is a bug_fix and the affected versions\n",
    "    bug_fix = 0\n",
    "    f_keys = get_fixed_bugs(commit_hash)\n",
    "    if len(f_keys) != 0:\n",
    "        bug_fix = 1\n",
    "            \n",
    "    for file_name, changes in file_changes.items():\n",
    "        #print(key, value)\n",
    "        update_counters(file_dict, file_name, author_name, changes)\n",
    "        \n",
    "        f = file_dict[file_name]\n",
    "        #Authorship and size:\n",
    "        try:\n",
    "            blame = git.blame(commit_hash, \"--\", file_name)\n",
    "            authorship = get_authorship(blame, f.author_dict.keys())\n",
    "            # IF YOU DON'T CONSIDER THE WHOLE HISTORY, THEN THESE AUTHORED LINES COUNT WILL\n",
    "            # NOT SUM TO THE TOTAL SIZE, BECAUSE THERE CAN BE STILL IN THE FILE LINES FROM AN AUTHOR\n",
    "            # THAT NEVER CONTRIBUTED IN OUR TIME WINDOW\n",
    "            size = len(blame.split(\"\\n\")) - 1\n",
    "            comments = count_comments(blame)\n",
    "            \n",
    "            #Authorship metrics\n",
    "            compl_authorship = get_complete_authorship(commit_hash, file_name)\n",
    "            total_current_authors = len(compl_authorship)\n",
    "            max_authorship = max(compl_authorship.values())\n",
    "\n",
    "        except:\n",
    "            #This happens if the file has been deleted by the commit\n",
    "            size = 0\n",
    "            comments = 0\n",
    "\n",
    "        for author, author_counter in f.author_dict.items():\n",
    "            wr.writerow([project_folder, #project\n",
    "                         file_name, #file\n",
    "                         commit_hash, #sha\n",
    "                         author, #author\n",
    "                         #Lines added\n",
    "                         author_counter.lines_added, #author_file_tot_added\n",
    "                         (changes.added if author == author_name else 0), #author_file_added_this_commit\n",
    "                         f.tot_lines_added, #file_tot_added\n",
    "                         #Lines deleted\n",
    "                         author_counter.lines_deleted, #author_file_tot_deleted\n",
    "                         (changes.deleted if author == author_name else 0), #author_file_deleted_this_commit\n",
    "                         f.tot_lines_deleted, #file_tot_deleted\n",
    "                         #Commits\n",
    "                         author_counter.commits, #author_file_commits\n",
    "                         f.tot_commits, #file_tot_commits\n",
    "                         #Authorship\n",
    "                         (authorship[author] if size != 0 else 0), #current_lines_authored\n",
    "                         size, #current_file_size\n",
    "                         comments, #current_comment_lines\n",
    "                         max_authorship, #max_current_author \n",
    "                         total_current_authors, #total_current_authors\n",
    "                         #Other stuff\n",
    "                         date, #commit_date\n",
    "                         bug_fix, #bug_fix\n",
    "                         f_keys, #fixed_bugs\n",
    "                         get_affected_versions(f_keys) #affected_versions\n",
    "                        ]) \n",
    "\n",
    "        #print()\n",
    "        #print(file_dict.get(key))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(implicated_list_file)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(df2, on=['sha', 'file'], how='left').fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(output_folder + '/' + project_folder + '_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example of file with a lot of owners and commits\n",
    "#df_test = df[df['file'] == 'lucene/core/src/java/org/apache/lucene/index/IndexWriter.java']\n",
    "#df_test[df_test['sha'] == '5ec48108df8997430e3e8b47c056d0d63c6d2db3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
