{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sh\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import pandas as pd\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LUCENE-SOLR\n",
    "project_folder = \"lucene\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"lucene-solr\"\n",
    "repository_link = \"https://github.com/apache/lucene-solr.git\"\n",
    "checkout_branch = \"trunk\"\n",
    "\n",
    "issues_folders = [\"issue_LUCENE\", \"issue_SOLR\"]\n",
    "issues_tags = [\"LUCENE\", \"SOLR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CAMEL\n",
    "project_folder = \"camel\"\n",
    "output_folder = \"out\"\n",
    "\n",
    "repository_folder = \"camel\"\n",
    "repository_link = \"https://github.com/apache/camel\"\n",
    "checkout_branch = \"master\"\n",
    "\n",
    "issues_folders = [\"issue_CAMEL\"]\n",
    "issues_tags = [\"CAMEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(i, l, step=1):\n",
    "    if i % step == 0:\n",
    "            print(\"\\r>> {}/{}\".format(i + 1, l), end=\"\")\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.getcwd() + '/' + project_folder + '/' + repository_folder):\n",
    "    print(\"Path doesn\\'t exists, cloning repo:\")\n",
    "    git = sh.git.bake(_cwd=project_folder)\n",
    "    git.clone(repository_link)\n",
    "else:\n",
    "    print(\"Repository exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "On branch trunk\n",
       "Your branch is up-to-date with 'origin/trunk'.\n",
       "\n",
       "nothing to commit, working directory clean"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git = sh.git.bake(_cwd=project_folder + '/' + repository_folder)\n",
    "git.checkout(checkout_branch)\n",
    "git.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_bug(file_path):\n",
    "    if not file.endswith('.json'):\n",
    "            return None\n",
    "    else:\n",
    "        bug_json_string = open(file_path).read()\n",
    "        bug = json.loads(bug_json_string)\n",
    "        bug_fields = bug.get('fields')\n",
    "        \n",
    "        if bug_fields['issuetype']['name'] != 'Bug':\n",
    "            return None\n",
    "   \n",
    "        if bug_fields['resolution'] == None:\n",
    "            return None \n",
    "                \n",
    "        if bug_fields['resolution']['name'] != 'Fixed':\n",
    "            return None\n",
    "    return bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fixed_bugs(commit_hash):\n",
    "    details = git.show(\"--name-only\",\"--pretty=format:%B\", commit_hash)\n",
    "    #init = details.split(':')[0].upper()\n",
    "    f_keys = []\n",
    "    \n",
    "    for tag in issues_tags:\n",
    "        keys = re.findall(tag + \"-[0-9]+\",str(details))\n",
    "        if len(keys) != 0:\n",
    "            for k in keys:\n",
    "                if bugs.get(k) != None:\n",
    "                    #Then it fixes a bug\n",
    "                    f_keys.append(k)\n",
    "    return f_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress for issue_LUCENE:\n",
      ">> 6641/6641\n",
      "Progress for issue_SOLR:\n",
      ">> 7721/7728\n",
      "4011 fixed bugs extracted.\n"
     ]
    }
   ],
   "source": [
    "#Extracting all the fixed bugs from the bug repo\n",
    "bugs = dict() #Dictionary of bugs indexed by TAG+ID (e.g. LUCENE-1234)\n",
    "for fld in issues_folders:\n",
    "    path = project_folder + '/' + fld\n",
    "    dir_list = os.listdir(os.getcwd() + '/' + path)\n",
    "    l = len(dir_list)\n",
    "    print()\n",
    "    print(\"Progress for \" + fld + \":\")\n",
    "    for idx, file in enumerate(dir_list):\n",
    "        print_progress(idx,l,10)\n",
    "        bug = extract_bug(path + '/' + file)\n",
    "        if(bug == None):\n",
    "            continue\n",
    "        bugs[bug['key'].upper()] = bug\n",
    "\n",
    "print()\n",
    "print(len(bugs), \"fixed bugs extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits = []\n",
    "\n",
    "log = git.log(\"--reverse\", \"--pretty=format:%H\")\n",
    "for c_hash in log:\n",
    "    if(c_hash.endswith('\\n')):\n",
    "        c_hash = c_hash[:-1]\n",
    "    commits.append(c_hash)\n",
    "len(commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      ">> 2251/16308"
     ]
    }
   ],
   "source": [
    "#Splits the bug fixing ones from the others\n",
    "\n",
    "fix_commits = [] #List that will be filled with couples (commit, bugs-fixed)\n",
    "non_fix_commits = [] #List that will be filled only with commit hashes\n",
    "l = len(commits)\n",
    "print(\"Progress:\")\n",
    "for idx, c in enumerate(commits):\n",
    "    \n",
    "    print_progress(idx, l, 10)\n",
    "        \n",
    "    details = git.show(\"--name-only\",\"--pretty=format:%B\", c)\n",
    "    files = git.show(\"--name-only\",\"--pretty=format:\",c)\n",
    "    \n",
    "    \n",
    "    f_keys = get_fixed_bugs(c)    \n",
    "    if len(f_keys) != 0:\n",
    "        fix_commits.append((c,f_keys))\n",
    "    else:\n",
    "        non_fix_commits.append(c)\n",
    "        \n",
    "#Some commits cite more than one issue...which lines are the bug fix, if one of the two is only an improvement ?\n",
    "#HP: we consider all the removed lines as implicated (fix-inducing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(fix_commits)) #Number of LUCENE-SOLR bug fixing commits\n",
    "print(len(non_fix_commits)) #Number of LUCENE-SOLR non bug fixing commits\n",
    "print(len(commits)) #Number of LUCENE-SOLR commits\n",
    "#We can see that on average half of the commits were only solr related, so we discarded them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bug_commits(commit_hash, line_num, bug_hash):\n",
    "    # checkout previous commit\n",
    "    git.checkout(\"--force\", commit_hash + \"^\")\n",
    "\n",
    "    # Go through all the files that have been changed\n",
    "    for key_file_name in line_num:\n",
    "        ## Check if file is a java file if not continue with next file\n",
    "        if(key_file_name.find('.java') == -1):\n",
    "            continue\n",
    "        \n",
    "        # blame file to see when the lines where last changed (on previous commit)\n",
    "        with open(project_folder + '_blame_file.txt', 'wb+') as file:\n",
    "            # --root is added to see boundary commits as normal commits\n",
    "            cmd = [\"git \" + \"-C ./\"+ project_folder + '/' + repository_folder + '/' +\" blame -l --root \" + key_file_name]\n",
    "            gitBlame = subprocess.Popen(cmd, shell=True, universal_newlines=True, stdout=file)\n",
    "            gitBlame.wait()\n",
    "            file.flush()\n",
    "            \n",
    "        output_blame = \"\"\n",
    "        with open(project_folder + '_blame_file.txt', 'rb+') as file:\n",
    "            output_blame = file.read()\n",
    "\n",
    "        # Cut output up in separate lines\n",
    "        blame_output = output_blame.decode(\"latin1\")        \n",
    "        blame_output_split = blame_output.split('\\n')\n",
    "                \n",
    "        # Get hash for all the lines that have been changed.\n",
    "        for i in line_num[key_file_name]:\n",
    "            line = blame_output_split[i-1]\n",
    "            hash_of_line = line.split(' ')[0]\n",
    "            \n",
    "            if bug_hash.get(hash_of_line) == None:\n",
    "                bug_hash[hash_of_line] = set([key_file_name])\n",
    "            else:\n",
    "                bug_hash[hash_of_line].add(key_file_name)\n",
    "            \n",
    "    return bug_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_added_lines(commitHash):\n",
    "    \n",
    "    # Get diff of current and previous commit and store this in a file\n",
    "    with open(project_folder + '_diff_file.txt', 'wb+') as file:\n",
    "        cmd = [\"git \" + \"-C ./\" + project_folder + '/' + repository_folder \n",
    "               + '/' + \" diff --no-color \" + commitHash +'^ ' + commitHash]\n",
    "        gitDiff = subprocess.Popen(cmd, shell=True, universal_newlines=True, stdout=file)\n",
    "        gitDiff.wait()\n",
    "        file.flush()\n",
    "\n",
    "    # Get diff of the commit\n",
    "    output_diff = \"\"\n",
    "    with open(project_folder + '_diff_file.txt', 'rb+') as file:\n",
    "        output_diff = file.read()\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    # Cut output up in separate lines\n",
    "    lines = output_diff.decode(\"latin1\").split('\\n')\n",
    "    \n",
    "    line_num = dict()\n",
    "    start_line = 0\n",
    "    name_of_file = \"\"\n",
    "    i = 0\n",
    "    name_file_set = set()\n",
    "\n",
    "    # Go through the diff output to determine line number(s) of deleted lines\n",
    "    for line in lines:\n",
    "        # Header where the name of the file is located.\n",
    "        if line[0:4] == \"diff\":\n",
    "            name_of_file = line.split(' b/')[-1]\n",
    "\n",
    "\n",
    "        # New section of changed code find starting line number\n",
    "        elif line[0:2] == \"@@\":\n",
    "            lineNum = re.findall('\\-[0-9]+\\,',line)\n",
    "            start_line = int(re.findall('\\-[0-9]+',line)[0][1:])\n",
    "            i = 0\n",
    "\n",
    "        # Lines that has been changed\n",
    "        elif (line[0:2] == \"- \"):\n",
    "            if line_num.get(name_of_file) == None:\n",
    "                # create set of lines that have been changed for each file\n",
    "                line_num[name_of_file] = []\n",
    "                name_file_set.add(name_of_file)\n",
    "            # Add lines to the set that have been changed\n",
    "            line_num[name_of_file].append(start_line + i);\n",
    "            i += 1\n",
    "\n",
    "\n",
    "        # Indentaion infront of a line of code that hasn't changed\n",
    "        elif line[0:2] == \"  \":\n",
    "            i += 1\n",
    "            \n",
    "    return line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get time between bug and fix\n",
    "# INPUT: Bug and fix hash\n",
    "# OUTPUT: time between the commits\n",
    "def get_time_between_commits(bug_hash, fix_hash):\n",
    "    file = open(project_folder + '_time_bug.txt', 'w+', encoding=\"ISO-8859-1\")\n",
    "    git.show(\"-s\", \"--format=%ci\", bug_hash, _out=\"time_bug.txt\").wait()\n",
    "    output_show_bug = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    file = open(project_folder + '_time_fix.txt', 'w+', encoding=\"ISO-8859-1\")\n",
    "    git.show(\"-s\", \"--format=%ci\", fix_hash, _out=\"time_fix.txt\").wait()\n",
    "    output_show_fix = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    time_bug = parser.parse(output_show_bug).replace(tzinfo=None)\n",
    "    time_fix = parser.parse(output_show_fix).replace(tzinfo=None)\n",
    "    \n",
    "    delta_time = time_fix-time_bug\n",
    "    return delta_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = len(fix_commits)\n",
    "fix_to_bug_dict = dict()\n",
    "bug_dict = dict()\n",
    "\n",
    "df = pd.DataFrame(columns=('SHA_fix', 'SHA_bug', 'file', 'time_in_days'))\n",
    "location = 0\n",
    "\n",
    "l = len(fix_commits)\n",
    "\n",
    "# Get the implicated lines\n",
    "new_lines = get_added_lines(fix_hash)\n",
    "# Get the hash of the implicated lines and to which file they belong\n",
    "bug_dict = get_bug_commits(fix_hash, new_lines, bug_dict)\n",
    "\n",
    "\n",
    "# Calculate the time between commit and fix\n",
    "for key, file_name in bug_dict.items():\n",
    "    for file in file_name:\n",
    "        time = get_time_between_commits(key, fix_hash)\n",
    "        df.loc[location] = [fix_hash, key, file, time.days]\n",
    "        location +=1\n",
    "\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = len(fix_commits)\n",
    "fix_to_bug_dict = dict()\n",
    "bug_dict = dict()\n",
    "df = pd.DataFrame(columns=('SHA_fix', 'SHA_bug', 'file', 'time_in_days'))\n",
    "location = 0\n",
    "\n",
    "l = len(fix_commits)\n",
    "# Iterate through all the fix commits\n",
    "for idx, fix_hash in enumerate(fix_commits):\n",
    "    bug_dict.clear()\n",
    "    # Get the implicated lines\n",
    "    new_lines = get_added_lines(fix_hash[0])\n",
    "    # Get the hash of the implicated lines and to which file they belong\n",
    "    bug_dict = get_bug_commits(fix_hash[0], new_lines, bug_dict)\n",
    "    \n",
    "    # Calculate the time between commit and fix\n",
    "    for key, file_name in bug_dict.items():\n",
    "        for file in file_name:\n",
    "            time = get_time_between_commits(key, fix_hash[0])\n",
    "            df.loc[location] = [fix_hash[0], key, file, time.days]\n",
    "            location +=1\n",
    "    \n",
    "    print_progress(idx, l,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(output_folder + '/' +  project_folder + '_implicated_fix_time.csv', index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sh.rm(project_folder + '_blame_file.txt')\n",
    "sh.rm(project_folder + '_diff_file.txt')\n",
    "sh.rm(project_folder + '_time_bug.txt')\n",
    "sh.rm(project_folder + '_time_fix.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
